{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "经典卷积神经网络.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOw2mvPgMyXDKSXUcSiRqbm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangdaming155/dive-into-deep-learning2/blob/main/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "计算机视觉的架构：\n",
        "* 平移不变性\n",
        "* 局部性\n",
        "\n",
        "感受野（receptive field）是指在前向传播期间可能影响计算的所有元素（来自所有先前层）"
      ],
      "metadata": {
        "id": "SN7N29PUChZs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ev0OXdzW7d1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ba024a-624b-4402-d5e4-54a125d746bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/d2l-zh')"
      ],
      "metadata": {
        "id": "D4EaIXmzI0Uu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "-al9fAcGJBBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "def corr2d(X, K):  \n",
        "    \"\"\"计算二维互相关运算\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y"
      ],
      "metadata": {
        "id": "n0FSmT0DJJ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 这里卷积核赋予权重，从而进行计算\n",
        "class Conv2D(nn.Module):\n",
        "  def __init__(self,kernel_size):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.rand(kernel_size))  #torch.rand 上（0,1）上的均匀分布\n",
        "    self.bias = nn.Parameter(torch.zeros(1))\n",
        "  \n",
        "  def forward(self,X):\n",
        "    return corr2d(X,self.weight) + self.bias\n",
        "\n"
      ],
      "metadata": {
        "id": "Es0XSbLeKlQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 图像中的目标检测\n",
        "X = torch.ones((6,8))\n",
        "X[:,2:6] = 0\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNjLz55aO-KV",
        "outputId": "577d5c75-c524-49f2-cb42-2fc62924bc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[1.0, -1.0]])"
      ],
      "metadata": {
        "id": "wquG-tm0PXVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = corr2d(X, K)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwxFhMZRQDN5",
        "outputId": "4fecaebf-1a07-45ba-a4d8-4f67969d1c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X.t(),K) #转置函数"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_n5Th2oQISq",
        "outputId": "2e55a8c6-8d0f-4b89-ade2-a9a130243f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"学习卷积核\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QvfDb2-qQ6mJ",
        "outputId": "58824f38-f5b6-47ff-a08b-8e310ed3d134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'学习卷积核'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构造一个二维卷积层，它具有一个1个输出通道和形状为（1,2）的卷积核\n",
        "conv2d = nn.Conv2d(1,1,kernel_size=(1,2),bias=False)  # 分别对应输入输出通道和核的大小以及bias\n",
        "\n",
        "#这个二维卷积层使用四维输入和输出格式（批量大小，通道、高度和宽度）\n",
        "#批量大小和通道数为1\n",
        "X = X.reshape((1,1,6,8))\n",
        "Y = Y.reshape((1,1,6,7))\n",
        "lr = 3e-2 #学习率\n",
        "\n",
        "for i in range(16):\n",
        "  Y_hat = conv2d(X)\n",
        "  l = (Y_hat - Y)**2\n",
        "  conv2d.zero_grad()\n",
        "  l.sum().backward()\n",
        "  #迭代卷积核\n",
        "  conv2d.weight.data[:] -= lr*conv2d.weight.grad\n",
        "  if(i+1)%2 == 0:\n",
        "    print(f'epoch{i+1},loss{l.sum():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4mNlYaRB_g",
        "outputId": "6c4ba2ad-9498-4b60-a1a1-4d776778ca3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch2,loss10.883\n",
            "epoch4,loss3.199\n",
            "epoch6,loss1.099\n",
            "epoch8,loss0.415\n",
            "epoch10,loss0.164\n",
            "epoch12,loss0.066\n",
            "epoch14,loss0.027\n",
            "epoch16,loss0.011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d.weight.data.reshape((1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13xk9fRdTR9-",
        "outputId": "c36bcf0d-dd3a-42e1-dd48-060cb9db7c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0100, -0.9884]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zqk43qVU64p",
        "outputId": "fc31c0c1-f88d-406c-e49c-390a5245dc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.0100, -0.9884]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 填充和步幅"
      ],
      "metadata": {
        "id": "JvoezUtPV7T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
        "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
        "def comp_conv2d(conv2d, X):\n",
        "    # 这里的（1，1）表示批量大小和通道数都是1\n",
        "    X = X.reshape((1, 1) + X.shape)\n",
        "    Y = conv2d(X)\n",
        "    # 省略前两个维度：批量大小和通道\n",
        "    return Y.reshape(Y.shape[2:])\n",
        "\n",
        "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n",
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)   #为3，默认为3*3\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BNRxUmUVD30",
        "outputId": "59497771-0e10-4666-c53b-052a38e08835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))    #记住向下取整\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ6CwuxwWsip",
        "outputId": "4428ff03-a135-41a0-bcfa-82d6ebd51475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icfkAS7pWwSM",
        "outputId": "5fe75968-0c78-4e90-cea2-36a1ba2fe503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKsEFcbbjCvK",
        "outputId": "1ca94a0c-354f-4e47-9bb8-e200457828d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nTU3cMTcjOlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "吴恩达，n+2P-f/s  + 1"
      ],
      "metadata": {
        "id": "Wm5ElfPdkwIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"多输入多输出通道\"\"\""
      ],
      "metadata": {
        "id": "x9dhHfrfk_XU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b2c1b91-1f34-4ba6-e210-4a8edf68810f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'多输入多输出通道'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "PgA0Ms9Lv_cl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in(X,K):\n",
        "  # 先遍历第一个通道的x和k，再把它们相加\n",
        "  return sum(d2l.corr2d(x,k)for x, k in zip(X,K))"
      ],
      "metadata": {
        "id": "j1tYP9IqwFsg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(zip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lYB1jOvw2r-",
        "outputId": "250d48d1-1f4e-4a82-cd2c-7c9549ce75e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class zip in module builtins:\n",
            "\n",
            "class zip(object)\n",
            " |  zip(*iterables) --> zip object\n",
            " |  \n",
            " |  Return a zip object whose .__next__() method returns a tuple where\n",
            " |  the i-th element comes from the i-th iterable argument.  The .__next__()\n",
            " |  method continues until the shortest iterable in the argument sequence\n",
            " |  is exhausted and then it raises StopIteration.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __next__(self, /)\n",
            " |      Implement next(self).\n",
            " |  \n",
            " |  __reduce__(...)\n",
            " |      Return state information for pickling.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "\n",
        "corr2d_multi_in(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NopLbQTw61t",
        "outputId": "78c27310-2735-4ef6-d324-7df5b1fb1095"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  72.],\n",
              "        [104., 120.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "多输出通道"
      ],
      "metadata": {
        "id": "D-ic5GLDx5-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#互相关函数\n",
        "def corr2d_multi_in_out(X,K):\n",
        "  #迭代K的第0维度\n",
        "  #结果叠加\n",
        "  return torch.stack([corr2d_multi_in(X,k) for k in K],0)"
      ],
      "metadata": {
        "id": "NwP8MUwXxiOP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.stack((K,K+1,K+2),0)\n",
        "K.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEB2O08-y1lu",
        "outputId": "e4d4ac28-b3c1-4352-ffd2-5b69d11a1ed3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"关于torch.stack的用法，粘接剂\"\"\"\n",
        "# 假设是时间步T1\n",
        "T1=torch.tensor([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\n",
        "# 假设是时间步T2\n",
        "T2=torch.tensor([[10, 20, 30],[40, 50, 60],[70, 80, 90]])"
      ],
      "metadata": {
        "id": "-Xp9hbG4zGPk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unexpected index 缩进错误，检查是否顶头写了"
      ],
      "metadata": {
        "id": "fskwDzep0tgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.stack((T1,T2),dim=0))\n",
        "print(torch.stack((T1,T2),dim=1))\n",
        "print(torch.stack((T1,T2),dim=2).shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aTDKdLazz7d",
        "outputId": "ff350c3b-daef-4572-b146-121897d2845e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [ 7,  8,  9]],\n",
            "\n",
            "        [[10, 20, 30],\n",
            "         [40, 50, 60],\n",
            "         [70, 80, 90]]])\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [10, 20, 30]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [40, 50, 60]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [70, 80, 90]]])\n",
            "torch.Size([3, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d_multi_in_out(X,K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlkK2HTX1BE2",
        "outputId": "c10a3b07-176f-41de-a39d-d4fed9d857f0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 56.,  72.],\n",
              "         [104., 120.]],\n",
              "\n",
              "        [[ 76., 100.],\n",
              "         [148., 172.]],\n",
              "\n",
              "        [[ 96., 128.],\n",
              "         [192., 224.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 1*1 卷积层降低通道数"
      ],
      "metadata": {
        "id": "fd5LyPo41fFX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = X.reshape((c_i, h * w))\n",
        "    K = K.reshape((c_o, c_i))\n",
        "    # 全连接层中的矩阵乘法\n",
        "    Y = torch.matmul(K, X)\n",
        "    return Y.reshape((c_o, h, w))"
      ],
      "metadata": {
        "id": "a229uD_k41dj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.normal(0, 1, (3, 3, 3))\n",
        "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
        "\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
      ],
      "metadata": {
        "id": "887j1j2f5FaR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wN5N9Soh5JLJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}